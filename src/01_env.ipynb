{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from known.basic import Remap\n",
    "from tqdm import tqdm\n",
    "import torch as tt\n",
    "import torch.nn as nn\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "default_device = 'cuda' if tt.cuda.is_available() else 'cpu'\n",
    "factory = dict(device=default_device, dtype=tt.float32)\n",
    "\n",
    "\n",
    "import deep, maco\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<maco.core.WorkersEnv at 0x1aec81de110>,\n",
       " <maco.core.WorkersEnv at 0x1aeca253310>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tenv = config.tenvF()\n",
    "venv = config.venvF()\n",
    "tenv, venv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test Result]:\n",
      "            \tTotal-Episodes\t[5]\n",
      "            \tMean-Reward\t[-22.379399999999997]\n",
      "            \tMedian-Reward\t[-23.242999999999995]\n",
      "            \tMax-Reward\t[-17.439]\n",
      "            \tMin-Reward\t[-27.351999999999997]\n",
      "            \n",
      "[Test Result]:\n",
      "            \tTotal-Episodes\t[5]\n",
      "            \tMean-Reward\t[-21.839199999999998]\n",
      "            \tMedian-Reward\t[-21.416999999999998]\n",
      "            \tMax-Reward\t[-20.567]\n",
      "            \tMin-Reward\t[-24.386]\n",
      "            \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-22.109299999999998, 60.0, -44.218599999999995, 120.0, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mean_return, mean_steps, sum_return, sum_steps, acts=deep.rl.Eval.validate_policy(\n",
    "    envs=[tenv, venv],\n",
    "    pie=deep.rl.RIE(0, venv.A),\n",
    "    episodes = 5,\n",
    ")\n",
    "mean_return, mean_steps, sum_return, sum_steps, len(acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESET]\n",
      "[TERM]: Steps:[60], Return:[-20.077]\n",
      "[RESET]\n",
      "[TERM]: Steps:[60], Return:[-12.218]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-16.1475, 60.0, -32.295, 120.0, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mean_return, mean_steps, sum_return, sum_steps, acts=deep.rl.Eval.validate_policy_once(\n",
    "    envs=[tenv, venv],\n",
    "    pie=deep.rl.RIE(0, venv.A), \n",
    "    episodic_verbose=1,\n",
    ")\n",
    "mean_return, mean_steps, sum_return, sum_steps, len(acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test Result]:\n",
      "            \tTotal-Episodes\t[5]\n",
      "            \tMean-Reward\t[-22.010600000000004]\n",
      "            \tMedian-Reward\t[-21.524]\n",
      "            \tMax-Reward\t[-17.648999999999997]\n",
      "            \tMin-Reward\t[-29.239]\n",
      "            \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-22.010600000000004, 60.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_return, mean_steps, test_returns, test_steps, test_actions = deep.rl.Eval.eval_policy(\n",
    "    env=venv,\n",
    "    pie=deep.rl.RIE(0, venv.A),\n",
    "    episodes=5\n",
    ")\n",
    "mean_return, mean_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_returns, test_steps, test_actions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESET]\n",
      "[TERM]: Steps:[60], Return:[-23.121000000000002]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-23.121000000000002,\n",
       " 60,\n",
       " [3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_returns, test_steps, test_actions  = deep.rl.Eval.test_policy(\n",
    "    env=venv,\n",
    "    pie=deep.rl.RIE(0, venv.A),\n",
    "    verbose=1\n",
    ")\n",
    "test_returns, test_steps, test_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = np.random.randint(0, venv.A, size=venv.T)\n",
    "sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_returns, test_steps, test_actions  = deep.rl.Eval.test_policy(\n",
    "    env=venv,\n",
    "    pie=deep.rl.VIE(sol),\n",
    "    verbose=1\n",
    ")\n",
    "test_returns, test_steps, test_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_returns, test_steps, test_actions  = deep.rl.Eval.test_solution(\n",
    "    env=venv,\n",
    "    acts=sol,\n",
    "    verbose=1\n",
    ")\n",
    "test_returns, test_steps, test_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env=venv\n",
    "\n",
    "rie = deep.rl.RIE(0, env.A)\n",
    "s, t, d= env.reset()\n",
    "print(f'{env.obsW=}, {env.pending=}')\n",
    "cr = 0.0\n",
    "while not d:\n",
    "    a = rie.predict()\n",
    "    s, t, d, r = env.step(a)\n",
    "    print(f'{env.obsW=}, {env.pending=}, {env.itask=}, {a=}, {t=}, {d=}, {r=}')\n",
    "    cr+=r\n",
    "print(f'Return = {cr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env=venv\n",
    "\n",
    "vie = deep.rl.VIE(np.random.randint(0, env.A, size=env.T))\n",
    "s, t, d= env.reset()\n",
    "print(f'{env.obsW=}, {env.pending=}')\n",
    "cr = 0.0\n",
    "while not d:\n",
    "    a = rie.predict(t)\n",
    "    s, t, d, r = env.step(a)\n",
    "    print(f'{env.obsW=}, {env.pending=}, {env.itask=}, {a=}, {t=}, {d=}, {r=}')\n",
    "    cr+=r\n",
    "print(f'Return = {cr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maco import fda\n",
    "\n",
    "env = venv\n",
    "n_actions = env.A\n",
    "n_steps =   env.T\n",
    "\n",
    "\n",
    "#====================================================================================================\n",
    "#====================================================================================================\n",
    "\n",
    "def randflowF(): return fda.random_flow(0, n_actions+1, n_steps)\n",
    "def flow2sol(x): return [ int(abs(i)) % n_actions for i in x ]\n",
    "def flowcost(x): return deep.rl.Eval.test_cost(env,  flow2sol(x))\n",
    "\n",
    "#====================================================================================================\n",
    "#====================================================================================================\n",
    "\n",
    "\n",
    "#print(f'{placement=}')\n",
    "top_flows =[(np.zeros(n_steps) + j) for j in range(0, n_actions)] \n",
    "   \n",
    "Flow_X, Flow_fitness  = \\\n",
    "fda.optimize(   MAXITER=    1000,\n",
    "                randflowF=  randflowF,\n",
    "                costF=      flowcost,\n",
    "                beta=       15,\n",
    "                alpha=      15,\n",
    "                base_flows= top_flows,\n",
    "                seed=       None)\n",
    "\n",
    "for i,(fx, fi) in enumerate(zip(Flow_X, Flow_fitness)):\n",
    "    print(f'{i=} : {flow2sol(fx)=} : {fi=}')\n",
    "\n",
    "# select top flows to continue\n",
    "selected_flows=[]\n",
    "selected_fitness = []\n",
    "for flow,fcost in zip(Flow_X, Flow_fitness):\n",
    "    sol = flow2sol(flow)\n",
    "    if sol not in selected_flows: \n",
    "        selected_flows.append(sol)\n",
    "        selected_fitness.append(fcost)\n",
    "selected_n = len(selected_flows)\n",
    "\n",
    "sorted_cost = np.argsort(selected_fitness)\n",
    "top_flows = [(np.array(selected_flows[sorted_cost[top]]), selected_fitness[sorted_cost[top]]) for top in range(selected_n)]\n",
    "#top_costs = [selected_fitness[sorted_cost[top]] for top in range(min(n_top, selected_n))]\n",
    "\n",
    "print(f'\\nSORTED')\n",
    "for i,(fx, fi) in enumerate(top_flows):\n",
    "    print(f'{i=} : {fx=} : {fi=}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = venv\n",
    "pie = deep.rl.S2SDQN(\n",
    "    n_actions = env.A,\n",
    "    embed_dim = 32,\n",
    "\n",
    "    encoder_block_size = env.T,\n",
    "    encoder_vocab_count = env.task_vocab.count,\n",
    "    encoder_hidden_dim = 64,\n",
    "    encoder_activation = nn.ReLU(),\n",
    "    encoder_num_heads = 4,\n",
    "    encoder_num_layers = 2,\n",
    "    encoder_norm_eps = 0.0, # final norm # keep zero to not use norm\n",
    "    encoder_dropout = 0.0,\n",
    "    encoder_norm_first = True,\n",
    "\n",
    "    decoder_block_size = env.T,\n",
    "    decoder_vocab_count = env.worker_vocab.count,\n",
    "    decoder_hidden_dim = 64,\n",
    "    decoder_activation = nn.ReLU(),\n",
    "    decoder_num_heads = 4,\n",
    "    decoder_num_layers = 2,\n",
    "    decoder_norm_eps = 0.0, # final norm # keep zero to not use norm\n",
    "    decoder_dropout = 0.0,\n",
    "    decoder_norm_first = True,\n",
    "\n",
    "    dense_layer_dims = [64 ,64, 64],\n",
    "    dense_actFs = [nn.Tanh(), nn.ReLU() ],\n",
    "    dense_bias = True,\n",
    "\n",
    "    xavier_init = False,\n",
    "\n",
    "    has_target = True, \n",
    "    **factory)\n",
    "\n",
    "deep.modular.count(pie.theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie.eval()\n",
    "\n",
    "\n",
    "s, t, d= env.reset()\n",
    "print(f'{env.obsW=}, {env.pending=}')\n",
    "cr = 0.0\n",
    "while not d:\n",
    "    print(f'\\n{t=}')\n",
    "    a = pie.predict(s, t)\n",
    "    s, t, d, r = env.step(a)\n",
    "    print(f'{env.obsW=}, {env.pending=}, {env.itask=}, {a=}, {t=}, {d=}, {r=}')\n",
    "    cr+=r\n",
    "print(f'Return = {cr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie.eval()\n",
    "\n",
    "\n",
    "s, t, d= env.reset()\n",
    "print(f'{env.obsW=}, {env.pending=}')\n",
    "cr = 0.0\n",
    "while not d:\n",
    "    print(f'\\n{t=}')\n",
    "    out, outx, a = pie.predict_(s, t)\n",
    "    print(out.shape, out)\n",
    "    print(outx.shape, outx)\n",
    "    s, t, d, r = env.step(a)\n",
    "    print(f'{env.obsW=}, {env.pending=}, {env.itask=}, {a=}, {t=}, {d=}, {r=}')\n",
    "    cr+=r\n",
    "print(f'Return = {cr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie.eval()\n",
    "\n",
    "with tt.no_grad():\n",
    "    s, t, d= env.reset()\n",
    "    s = tt.stack((s,s))\n",
    "    print(f'{s.shape=}, {env.obsW=}, {env.pending=}')\n",
    "\n",
    "    cr = 0.0\n",
    "    while not d:\n",
    "        print(f'\\n{t=}')\n",
    "        \n",
    "        out = pie.forward(s.to(device=default_device))\n",
    "        print('out', out.shape, out)\n",
    "        outX = tt.argmax(out, dim=-1)\n",
    "        print('outX', outX.shape, outX)\n",
    "        a = outX[:,t]\n",
    "        print('a', a.shape, a)\n",
    "        break\n",
    "        s, t, d, r = env.step(a)\n",
    "        print(f'{env.obsW=}, {env.pending=}, {env.itask=}, {a=}, {t=}, {d=}, {r=}')\n",
    "        cr+=r\n",
    "    print(f'Return = {cr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie.eval()\n",
    "\n",
    "with tt.no_grad():\n",
    "    \n",
    "    st, tt_, dt= tenv.reset()\n",
    "    sv, tv_, dv= venv.reset()\n",
    "\n",
    "    s = tt.stack((st,sv))\n",
    "    print(f'{s.shape=}')\n",
    "\n",
    "    d=(dt or dv)\n",
    "\n",
    "    crt, crv = 0.0, 0.0\n",
    "    while not (d):\n",
    "        print(f'\\n{tt_=}, {tv_=}')\n",
    "        \n",
    "        a= pie.predict_batch(s, tt_)\n",
    "        #print('a', a.shape, a)\n",
    "        st, tt_, dt, rt = tenv.step(a[0])\n",
    "        sv, tv_, dv, rv = venv.step(a[1])\n",
    "        d=(dt or dv)\n",
    "        print(f'{a[0]=}, {tt_=}, {dt=}, {rt=}')\n",
    "        print(f'{a[1]=}, {tv_=}, {dv=}, {rv=}')\n",
    "        crt+=rt\n",
    "        crv+=rv\n",
    "    print(f'Return = {crt}, {crv}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
